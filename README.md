# ğŸ¤– GenAI Test Platform
**An AI-powered automated testing platform that generates comprehensive tests from code changes using LLMs.**

A complete CI/CD solution that automatically detects code changes, analyzes context, generates targeted tests using Large Language Models, and provides comprehensive coverage reporting.

---

## ğŸš€ **Complete Automated Workflow**

Push commits â†’ GitHub Actions automatically:
1. **Detects Changes** - Identifies modified Python files
2. **Builds Context** - Creates comprehensive analysis bundle  
3. **Installs Ollama** - Sets up LLM environment in CI
4. **Generates Tests** - Creates pytest files using AI
5. **Runs Tests** - Executes tests with coverage analysis
6. **Reports Results** - Comprehensive GitHub Actions summary

## âœ¨ **Key Features**

- ğŸ” **Smart Change Detection** - Git-based Python file analysis
- ğŸ§  **AI Test Generation** - Context-aware test creation using Qwen2.5-Coder
- ğŸ›¡ï¸ **Safety Validation** - AST parsing, import safety, retry logic
- ğŸ“Š **Coverage Analysis** - Comprehensive test coverage reporting
- ğŸ”„ **Complete CI Automation** - Zero manual intervention required
- ğŸ“ˆ **GitHub Integration** - Rich summaries and artifact uploads

---

## ğŸ¯ **POC Demonstration**

This repository demonstrates a complete **Proof of Concept** for automated test generation:

### **What It Generates**
- **Functional Tests**: Core logic validation
- **Edge Case Tests**: Boundary conditions and error handling  
- **Regression Tests**: Prevents breaking existing functionality
- **Comprehensive Coverage**: Multiple test approaches per function

### **Current Test Results**
- âœ… **30 generated tests** across multiple modules
- ğŸ“Š **28% coverage** with room for improvement
- ğŸ”§ **2 failing tests** (revealing actual code issues!)
- ğŸš€ **Fully automated pipeline** ready for production scaling

---

## ğŸ› ï¸ **Technologies & Architecture**

### **Core Stack**
- **ğŸ Python 3.10+** - Primary development language
- **ğŸ¤– Ollama + Qwen2.5-Coder** - Local LLM for test generation
- **ğŸ§ª pytest + coverage** - Testing framework and analysis
- **âš¡ GitHub Actions** - Complete CI/CD automation
- **ğŸ“Š Streamlit** - Demo dashboard (legacy component)

### **LLM Agent Components**
- `enhanced_context_builder.py` - Git diff analysis & context bundling
- `generate_tests.py` - AI-powered test generation with validation
- `run_tests.py` - Local test execution with coverage
- `code_analyzer.py` - Static code analysis and guidance

---

## ğŸš€ **Quick Start**

### **Automatic (Recommended)**
Just push your code changes to trigger the complete pipeline:

```bash
git add .
git commit -m "feat: your changes here"  
git push origin main
```

**â†’ Check GitHub Actions tab for complete automated results!**

### **Manual Local Testing**
```bash
# 1. Clone repository
git clone https://github.com/imcalledgautam/genai-test-platform.git
cd genai-test-platform

# 2. Install dependencies  
pip install -r requirements.txt

# 3. Build context bundle
python llm_agent/enhanced_context_builder.py

# 4. Generate tests (requires Ollama)
python llm_agent/generate_tests.py

# 5. Run tests with coverage
python llm_agent/run_tests.py
```

---

## ğŸ“‚ **Repository Structure**

```
genai-test-platform/
â”œâ”€â”€ .github/workflows/           # GitHub Actions CI/CD
â”‚   â”œâ”€â”€ detect_changes.yml      # Main pipeline (complete automation)
â”‚   â””â”€â”€ run_tests.yml           # Standalone test runner
â”œâ”€â”€ llm_agent/                  # AI test generation engine
â”‚   â”œâ”€â”€ enhanced_context_builder.py  # Context analysis
â”‚   â”œâ”€â”€ generate_tests.py       # LLM test generation  
â”‚   â”œâ”€â”€ run_tests.py           # Test execution
â”‚   â””â”€â”€ prompt_template.txt     # LLM prompt template
â”œâ”€â”€ tests/generated/            # AI-generated test files
â”œâ”€â”€ code/                      # Sample application code
â”œâ”€â”€ ci_artifacts/              # Build artifacts & context bundles
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸ¯ **Next Steps & Roadmap**

### **Phase 2 Enhancements**
- ğŸ¨ **Risk-Based Prioritization** - Focus on high-impact changes
- ğŸ’¬ **Natural Language Interface** - Chat-based test requests
- ğŸ”§ **Self-Healing Tests** - Automatic test maintenance
- ğŸ“Š **Advanced Metrics** - Quality scoring and trends
- ğŸŒ **Multi-Language Support** - Beyond Python

### **Production Scaling**
- ğŸ—ï¸ **Self-Hosted Runners** - Dedicated CI infrastructure
- ğŸ” **Enterprise Security** - Advanced safety controls
- ğŸ“ˆ **Performance Optimization** - Faster test generation
- ğŸ”„ **Workflow Customization** - Team-specific configurations

---

## ğŸ¤ **Contributing**

This is a **Proof of Concept** demonstrating AI-powered test automation. 

**Current Status**: âœ… **Complete automated pipeline ready for production scaling**

**Key Achievement**: End-to-end workflow from code push â†’ AI analysis â†’ test generation â†’ execution â†’ reporting

---

## ğŸ“„ **License**

This project is open source and available under the [MIT License](LICENSE).

---

**ğŸš€ Ready to see AI-powered testing in action? Just push a commit and watch the magic happen!**
```
streamlit run dashboard.py
```
Data Source
The current data is mock data generated using Faker for demonstration purposes.

To generate your own transaction data, simply run:
```
python generate_mock_data.py
```

ğŸ¤ Contributing
Feel free to fork this repository, submit issues, and send pull requests. Contributions are welcome!
